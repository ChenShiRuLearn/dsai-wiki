## 一、引言

很长一段时间，核心NLP技术主要是机器学习方法，它们使用线性模型（如支持向量机或逻辑回归），通过非常高维但非常稀疏的特征向量进行训练。最近，该领域从这种稀疏输入的线性模型转换到密集输入的非线性神经网络模型，取得了一些成就。虽然大多数神经网络技术很容易应用，有时甚至可以直接替代旧的线性分类器，但在许多情况下，这是一个很大的进入障碍。在本教程中，我尝试为 NLP 从业人员（以及新人）提供基本背景，行话，工具和方法，使他们能够理解神经网络模型背后的原理，并将它们应用到自己的工作中。本教程预计将自成体系，同时在统一表示和框架下提供不同的方法。它重复了很多其他地方可用的材料。适当情况下，对于更高级的主题，它也指向外部来源。

这本入门书不是为那些将继续开发神经网络机器的下一步进展的人提供的综合资源（虽然它可能是一个很好的切入点）。 相反，它的目标读者是那些有兴趣利用现有的实用技术，并以实用和创造性的方式，将其应用于他们最喜欢的 NLP 问题的读者。 对于神经网络的更深入的一般讨论，背后的理论，高级优化方法和其他高级主题，读者可以参考其他现有资源。 尤其强烈推荐 Bengio 等人（2015 年）的书。

范围。本书重点在于，神经网络在语言处理任务中的应用。然而，神经网络语言处理的一些子领域，已经被排除在本教程的范围之外。这些包括广泛的语言建模和声学建模文献，使用神经网络进行机器翻译，以及将语言和其他信号（如图像和视频）（例如字幕生成）相结合的多模式应用。还没有讨论用于高效运行时性能的缓存方法，以及用于使用大量输出词汇和注意模型的高效训练方法。为了将它们用作其他模型的输入，词嵌入仅在需要理解的范围内讨论。其他无监督的方法，包括自编码器和递归自编码器，也不属于该范围。虽然在文中提到了神经网络在语言建模和机器翻译方面的一些应用，但它们的实验并不全面。

术语说明。 “特征”一词用于指代具体的语言输入，例如单词，后缀或词性标签。 例如，在一阶词性标注器中，这些特征可能是“当前词，上一个词，下一个词，上一个词”。 术语“输入向量”用于指代被提供给神经网络分类器的实际输入。 类似地，“输入向量条目”是指输入的特定值。 这与许多神经网络文献相反，其中“特征”一词在这两种用途之间被重载，主要用于指输入向量条目。

数学表示法。我使用粗体大写字母来表示矩阵（$\bf X$，$\bf Y$，$\bf Z$），并使用粗体小写字母来表示向量（$\bf b$）。 当有一系列相关的矩阵和向量（例如，每个矩阵对应于网络中的不同层）时，使用上标索引（$\bf W^1$，$\bf W^2$）。 对于罕见情况，我们希望表示矩阵或向量的幂，在要计算幂的式子周围添加一对括号：$\bf (W)^2$，$\bf (W^3)^2$。 除非另有说明，否则向量被假定为行向量。 我们使用 $\bf [v1; v2]$ 表示向量连接。

